{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "import random\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed) # cpu\n",
    "torch.cuda.manual_seed(random_seed) #gpu\n",
    "np.random.seed(random_seed) #numpy\n",
    "random.seed(random_seed) #random and transforms\n",
    "torch.backends.cudnn.deterministic=True # cudnn\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(random_seed + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/storage/wjwang/deconfounding/data/ml/data_4/'\n",
    "item_category = np.load(data_path+'item_category.npy', allow_pickle=True).item()\n",
    "category_list = np.load(data_path+'category_list.npy', allow_pickle=True).tolist()\n",
    "training_list = np.load(data_path+'/ml_1m/training_list.npy', allow_pickle=True).tolist()\n",
    "test_dict = np.load(data_path+'/ml_1m/testing_dict.npy', allow_pickle=True).item()\n",
    "item_feature = np.load(data_path+'/ml_1m/item_feature_file.npy', allow_pickle=True).item()\n",
    "item_idx = list(item_feature.keys())\n",
    "\n",
    "user_item_score = np.load('./FM_user_item_scores.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_user_cate_dis = {}\n",
    "for pair in training_list:\n",
    "    userID, itemID = pair\n",
    "    if userID not in training_user_cate_dis:\n",
    "        training_user_cate_dis[userID] = [0] * len(category_list)\n",
    "    categories = item_category[itemID]\n",
    "    for cate in categories:\n",
    "        training_user_cate_dis[userID][cate] += round(1.0/len(categories), 4)\n",
    "\n",
    "def sigmoid(x):\n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    return s\n",
    "\n",
    "def add_item_cate_dis(user_cate_dis, itemID):\n",
    "    categories = item_category[itemID]\n",
    "    tmp_user_cate_dis = [0] * len(category_list)\n",
    "    for cate in categories:\n",
    "        tmp_user_cate_dis[cate] = user_cate_dis[cate] + round(1.0/len(categories), 4)\n",
    "    return tmp_user_cate_dis\n",
    "\n",
    "def kl_div(p_dis, q_dis, alpha=0.01):\n",
    "    KL_res = 0\n",
    "    for index, p_value in enumerate(p_dis):\n",
    "        if p_value < 1e-5:\n",
    "            continue\n",
    "        q_value = (1-alpha) * q_dis[index] + alpha * p_dis[index]\n",
    "        KL_res += p_value*(np.log(p_value/q_value))\n",
    "    return KL_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     49
    ]
   },
   "outputs": [],
   "source": [
    "def computeTopNAccuracy(GroundTruth, predictedIndices, topN):\n",
    "    precision = [] \n",
    "    recall = [] \n",
    "    NDCG = [] \n",
    "    MRR = []\n",
    "    \n",
    "    for index in range(len(topN)):\n",
    "        sumForPrecision = 0\n",
    "        sumForRecall = 0\n",
    "        sumForNdcg = 0\n",
    "        sumForMRR = 0\n",
    "        for i in range(len(predictedIndices)):  # for a user,\n",
    "            if len(GroundTruth[i]) != 0:\n",
    "                mrrFlag = True\n",
    "                userHit = 0\n",
    "                userMRR = 0\n",
    "                dcg = 0\n",
    "                idcg = 0\n",
    "                idcgCount = len(GroundTruth[i])\n",
    "                ndcg = 0\n",
    "                hit = []\n",
    "                for j in range(topN[index]):\n",
    "                    if predictedIndices[i][j] in GroundTruth[i]:\n",
    "                        # if Hit!\n",
    "                        dcg += 1.0/math.log2(j + 2)\n",
    "                        if mrrFlag:\n",
    "                            userMRR = (1.0/(j+1.0))\n",
    "                            mrrFlag = False\n",
    "                        userHit += 1\n",
    "                \n",
    "                    if idcgCount > 0:\n",
    "                        idcg += 1.0/math.log2(j + 2)\n",
    "                        idcgCount = idcgCount-1\n",
    "                            \n",
    "                if(idcg != 0):\n",
    "                    ndcg += (dcg/idcg)\n",
    "                    \n",
    "                sumForPrecision += userHit / topN[index]\n",
    "                sumForRecall += userHit / len(GroundTruth[i])               \n",
    "                sumForNdcg += ndcg\n",
    "                sumForMRR += userMRR\n",
    "        \n",
    "        precision.append(round(sumForPrecision / len(predictedIndices), 4))\n",
    "        recall.append(round(sumForRecall / len(predictedIndices), 4))\n",
    "        NDCG.append(round(sumForNdcg / len(predictedIndices), 4))\n",
    "        MRR.append(round(sumForMRR / len(predictedIndices), 4))\n",
    "        \n",
    "    return precision, recall, NDCG, MRR\n",
    "\n",
    "def calibration(item_feature, test_dict, train_dict, user_pred, topN, cate_num):\n",
    "    C_KL = []\n",
    "    C_H = []\n",
    "    C_E = []\n",
    "    assert len(test_dict) == len(user_pred)\n",
    "    \n",
    "    alpha = 0.01 # refer to the setting in \"calibrated recommendation\"\n",
    "    for i, userID in enumerate(test_dict):\n",
    "        \n",
    "        history_items = train_dict[userID]\n",
    "        history_cate = np.array([0]*cate_num, dtype=np.float32)\n",
    "        for itemID in history_items:\n",
    "            history_cate += np.array(item_feature[itemID][1][-cate_num:], dtype=np.float32)\n",
    "        history_cate = history_cate/len(history_items)\n",
    "        \n",
    "        C_KL_u = []\n",
    "        C_H_u = []\n",
    "        C_E_u = []\n",
    "        for n in topN:\n",
    "            rec_list = user_pred[i][:n]\n",
    "            rec_cate = np.array([0]*cate_num, dtype=np.float32)\n",
    "            for itemID in rec_list:\n",
    "                rec_cate += np.array(item_feature[itemID][1][-cate_num:], dtype=np.float32)\n",
    "            rec_cate = rec_cate/len(rec_list)\n",
    "            C_KL_res = 0\n",
    "            C_H_res = 0\n",
    "            C_E_res = 0\n",
    "            for j, p_cate in enumerate(history_cate):\n",
    "                C_H_res += (np.sqrt(p_cate) - np.sqrt(rec_cate[j])) * (np.sqrt(p_cate) - np.sqrt(rec_cate[j]))\n",
    "                C_E_res += (p_cate-rec_cate[j]) * (p_cate-rec_cate[j])\n",
    "                if p_cate < 1e-5:\n",
    "                    continue\n",
    "                q_cate = (1-alpha) * rec_cate[j] + alpha * p_cate\n",
    "                C_KL_res += p_cate*(np.log(p_cate/q_cate))\n",
    "            C_KL_u.append(C_KL_res)\n",
    "            C_H_u.append(np.sqrt(C_H_res)/np.sqrt(2))\n",
    "            C_E_u.append(np.sqrt(C_E_res))\n",
    "        C_KL.append(C_KL_u)\n",
    "        C_H.append(C_H_u)\n",
    "        C_E.append(C_E_u)\n",
    "    C_KL = np.around(np.mean(C_KL, 0), 4).tolist()\n",
    "    C_H = np.around(np.mean(C_H, 0), 4).tolist()\n",
    "    C_E = np.around(np.mean(C_E, 0), 4).tolist()\n",
    "    return C_KL, C_H, C_E\n",
    "\n",
    "def print_results(train_RMSE, valid_result, test_result, calibration_results):\n",
    "    \"\"\"output the evaluation results.\"\"\"\n",
    "    if train_RMSE is not None:\n",
    "        print(\"[Train]: RMSE: {:.4f}\".format(train_RMSE))\n",
    "    if valid_result is not None: \n",
    "        print(\"[Valid]: Precision: {} Recall: {} NDCG: {} MRR: {}\".format(\n",
    "                            '-'.join([str(x) for x in valid_result[0]]), \n",
    "                            '-'.join([str(x) for x in valid_result[1]]), \n",
    "                            '-'.join([str(x) for x in valid_result[2]]), \n",
    "                            '-'.join([str(x) for x in valid_result[3]])))\n",
    "    if test_result is not None: \n",
    "        print(\"[Test]: Precision: {} Recall: {} NDCG: {} MRR: {}\".format(\n",
    "                            '-'.join([str(x) for x in test_result[0]]), \n",
    "                            '-'.join([str(x) for x in test_result[1]]), \n",
    "                            '-'.join([str(x) for x in test_result[2]]), \n",
    "                            '-'.join([str(x) for x in test_result[3]])))\n",
    "\n",
    "    if calibration_results is not None:\n",
    "        print(\"[Calibration]: C_KL: {} C_H: {} C_E: {}\".format(\n",
    "                            '-'.join([str(x) for x in calibration_results[0]]), \n",
    "                            '-'.join([str(x) for x in calibration_results[1]]), \n",
    "                            '-'.join([str(x) for x in calibration_results[2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda_list = [0, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "k = 100\n",
    "topN = [10, 20, 50, 100]\n",
    "st_time = time.time()\n",
    "for lamda in lamda_list:\n",
    "    user_ranking_list = []\n",
    "    user_test_gt = []\n",
    "    cnt = 0\n",
    "    for userID in user_item_score:\n",
    "\n",
    "        item_scores = [sigmoid(x) for x in user_item_score[userID]]\n",
    "        user_cate_dis = [0] * len(category_list)\n",
    "        item_set = []\n",
    "        item_rel_score = 0\n",
    "\n",
    "        for i in range(k):\n",
    "            max_f_score = 0\n",
    "            for j in range(len(item_idx)):\n",
    "                if cnt % 10 == 0:\n",
    "                    print(time.strftime(\"%H: %M: %S\", time.gmtime(time.time()-st_time)))\n",
    "                cnt+=1    \n",
    "                itemID = item_idx[j]\n",
    "                if itemID in item_set:\n",
    "                    continue\n",
    "                tmp_user_cate_dis = [x/(len(item_set)+1) for x in add_item_cate_dis(user_cate_dis, itemID)]\n",
    "                f_score = (1-lamda)*(item_rel_score + item_scores[j]) \\\n",
    "                                + lamda*(kl_div(training_user_cate_dis[userID], tmp_user_cate_dis))\n",
    "                if f_score > max_f_score:\n",
    "                    max_f_score = f_score\n",
    "                    add_item = itemID\n",
    "                    add_item_index = j\n",
    "            item_set.append(add_item)\n",
    "            item_rel_score = item_rel_score + item_scores[add_item_index]\n",
    "            user_cate_dis = add_item_cate_dis(user_cate_dis, add_item)\n",
    "        user_ranking_list.append(item_set)\n",
    "        user_test_gt.append(test_dict[userID])\n",
    "    test_result = computeTopNAccuracy(test_dict, user_ranking_list, topN)\n",
    "    print_results(None, None, test_result, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
